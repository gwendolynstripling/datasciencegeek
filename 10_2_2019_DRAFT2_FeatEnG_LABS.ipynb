{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": " 10.2.2019-DRAFT2 - FeatEnG - LABS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwendolynstripling/datasciencegeek/blob/master/10_2_2019_DRAFT2_FeatEnG_LABS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o8Qof7Cy165",
        "colab_type": "text"
      },
      "source": [
        "# Applying Feature Engineering to BigQuery ML Models - Part 1\n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "* Setup up the environbment\n",
        "* Create the project dataset\n",
        "* Create the feature engineering training table\n",
        "* Create and evaluate the  benchmark/baseline model\n",
        "* Extract numeric features\n",
        "* Perform a Feature cross\n",
        "* Evalute model performance\n",
        "\n",
        "## Introduction \n",
        "In this notebook, we utilize feature engineering to improve the prediction of the fare amount for a taxi ride in New York City based on numeric, categorical, temporal, distance, and coordinate features.  We will use BigQuery ML to build a taxifare prediction model, using feature engineering to improve and create a final model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ7ByvoXzpVI",
        "colab_type": "text"
      },
      "source": [
        "### Set up environment variables and load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbC1oBIbzqWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT = \"XXXXX\"  # Replace with your PROJECT\n",
        "REGION = \"XXXX\"            # Choose an available region for Cloud MLE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlnxjTfOzyyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"PROJECT\"] = PROJECT\n",
        "os.environ[\"REGION\"] = REGION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC9K9Dpx1ztf",
        "colab_type": "text"
      },
      "source": [
        "Check that the Google BigQuery library is installed and if not, install it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUQtASG10xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze | grep google-cloud-bigquery==1.6.1 || pip install google-cloud-bigquery==1.6.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0-vOB4y2BJM",
        "colab_type": "text"
      },
      "source": [
        "## The source dataset\n",
        "\n",
        "Our dataset is hosted in [BigQuery](https://cloud.google.com/bigquery/). The taxi fare data is a publically available dataset, meaning anyone with a GCP account has access. Click [here](https://console.cloud.google.com/bigquery?project=bigquery-public-data&p=nyc-tlc&d=yellow&t=trips&page=table) to acess the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTqTlSAWYt8N",
        "colab_type": "text"
      },
      "source": [
        "## Create the project dataset\n",
        "\n",
        "Although the source dataset is hosted in BigQuery, in this section you create a dataset to hold your table, add data to your project, then make the data table you'll query against.  As you recall, datasets help you control access to tables and views in a project. This lab uses only one table, but you still need a dataset to hold the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44T43EN-ZlvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the feature engineering dataset ...\n",
        "!bq mk feat_eng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-_TZtm_UFgd",
        "colab_type": "text"
      },
      "source": [
        "## Verify the dataset properties\n",
        "\n",
        "Verify that you created the dataset by viewing the dataset's properties with the bq show command.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A8HrwykUCOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#View dataset properties\n",
        "\n",
        "%%bigquery\n",
        "bq show feat_eng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2TuS1s9vREL",
        "colab_type": "text"
      },
      "source": [
        "## Create the training data table\n",
        "\n",
        "Since there is already a publicly available dataset, we can simply create the training data table.  Note the WHERE clause in the below query:  This clause allows us to TRAIN a portion of the data (e.g. one million rows versus a billion rows), which keeps your query costs down. \n",
        "\n",
        "* Note:  The dataset in the create table code below is the one created previously, e.g. \"feat_eng\".  The table name is \"feateng_training_data\".\n",
        "* **RUN** the query to create the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMNRractvREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE TABLE feat_eng.feateng_training_data \n",
        "AS\n",
        "SELECT\n",
        "  (tolls_amount + fare_amount) AS fare_amount,\n",
        "  passenger_count*1.0 AS passengers,\n",
        "  pickup_datetime,\n",
        "  pickup_longitude AS pickuplon,\n",
        "  pickup_latitude AS pickuplat,\n",
        "  dropoff_longitude AS dropofflon,\n",
        "  dropoff_latitude AS dropofflat\n",
        "\n",
        "\n",
        "FROM `nyc-tlc.yellow.trips`\n",
        "WHERE MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 10000) = 1\n",
        " \n",
        "  AND fare_amount >= 2.5\n",
        "  AND passenger_count > 0\n",
        "  AND pickup_longitude > -78\n",
        "  AND pickup_longitude < -70\n",
        "  AND dropoff_longitude > -78\n",
        "  AND dropoff_longitude < -70\n",
        "  AND pickup_latitude > 37\n",
        "  AND pickup_latitude < 45\n",
        "  AND dropoff_latitude > 37\n",
        "  AND dropoff_latitude < 45\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clnaaqQsXkwC"
      },
      "source": [
        "## Verify table creation\n",
        "\n",
        "Verify that you created the dataset by viewing the dataset's properties with the bq show command.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GgjFagjNiji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTION #1 - Verify table creation\n",
        "\n",
        "%%bigquery\n",
        "bq show feat_eng.feateng_training_data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RdTKphal-rn6",
        "colab": {}
      },
      "source": [
        "# OPTION 2 - Verify table creation\n",
        "\n",
        "%%bigquery\n",
        "-- LIMIT 0 is a free query; this allows us to check that the table exists.\n",
        "SELECT * FROM feat_eng.feateng_training_data \n",
        "LIMIT 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhgXan8wvREN",
        "colab_type": "text"
      },
      "source": [
        "### Create the Benchmark/Baseline Model\n",
        "\n",
        "Next, you create a linear regression baseline model with no feature engineering.  Recall that a model in BigQuery ML represents what an ML system has learned from the training data.  A baseline model is a solution to a problem without applying any machine learning techniques.  \n",
        "\n",
        "When creating a BQML model, you must specify the model type (in our case linear regression) and the input label (fare_amount).  Note also that we are using the training data table as the data source."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_5NlfU7oyT",
        "colab_type": "text"
      },
      "source": [
        "###Create the SQL statement to create the model \"Benchmark Model\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2odQpUn_7yCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SQL STATEMENT HERE: \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "84q4apNBvRER",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE MODEL feat_eng.benchmark_model\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  pickup_datetime,\n",
        "  pickuplon,\n",
        "  pickuplat,\n",
        "  dropofflon,\n",
        "  dropofflat\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq2KYJOM9ULC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "REMINDER:  The query takes several minutes to complete. After the first iteration is complete, your model (sample_model) appears in the navigation panel of the BigQuery web UI. Because the query uses a CREATE MODEL statement to create a model, you do not see query results.\n",
        "\n",
        "You can observe the model as it's being trained by viewing the Model stats tab in the BigQuery web UI. As soon as the first iteration completes, the tab is updated. The stats continue to update as each iteration completes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5d50Eic-X1",
        "colab_type": "text"
      },
      "source": [
        "Once the training is done, visit the [BigQuery Cloud Console](https://console.cloud.google.com/bigquery) and look at the model that has been trained. Then, come back to this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSgIJqN6vREV",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the benchmark model\n",
        "Note that BigQuery automatically split the data we gave it, and trained on only a part of the data and used the rest for evaluation.  After creating your model, you evaluate the performance of the regressor using the ML.EVALUATE function. The ML.EVALUATE function evaluates the predicted values against the actual data.\n",
        "\n",
        "NOTE: The results are also displayed in the BigQuery GUI console under the **Evaluation** tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_21sAIR7LZw",
        "colab_type": "text"
      },
      "source": [
        "###Create the SQL statement to EVALUATE the Benchmark Model.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ThB6PeRl77tk",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE THE Benchmark Model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "8mAXRTvbvRES",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.benchmark_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vJb1av908GBe"
      },
      "source": [
        "###Create the SQL statement to EVALUATE the Benchmark Model using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-JJCmYiC8GBi",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE THE Benchmark Model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDBNEuFa8V5j",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.benchmark_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJGbfYuD8a9d",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** Because you performed a linear regression, the results include the following columns:\n",
        "\n",
        "*   mean_absolute_error\n",
        "*   mean_squared_error\n",
        "*   mean_squared_log_error\n",
        "*   median_absolute_error\n",
        "*   r2_score\n",
        "*   explained_variance\n",
        "\n",
        "**Resource** for an explanation of the regression metrics:  [Regression Metrics](https://https://joshlawman.com/metrics-regression/)\n",
        "\n",
        "**Mean squared error** (MSE) measures the difference between the values our model predicted using the test set and the actual values. You can also think of it as the distance between your regression (best fit) line and the predicted values. A smaller value is better, and our model’s .0121 MSE is very good.\n",
        "\n",
        "**Note**:  An important metric in the evaluation results is the R2 score. The R2 score is a statistical measure that determines if the linear regression predictions approximate the actual data. 0 indicates that the model explains none of the variability of the response data around the mean. 1 indicates that the model explains all the variability of the response data around the mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW6fnqAW8vyI",
        "colab_type": "text"
      },
      "source": [
        "#### EXTRACT DayOfWeek from the pickup_datetime feature.\n",
        "\n",
        "* As you recall, DayOfWeek is an enum representing the 7 days of the week. This factory allows the enum to be obtained from the int value. The int value follows the ISO-8601 standard, from 1 (Monday) to 7 (Sunday). \n",
        "\n",
        "* Create a model titled \"model_1\" from the benchmark model and extract out the DayofWeek.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hkXTdLM--vpj",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EXTRACT ouT the DayofWeek from the pickup_datetime feature.\n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "ZQ0kT2jN-vpm",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.model_1\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  pickuplon,\n",
        "  pickuplat,\n",
        "  dropofflon,\n",
        "  dropofflat\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24XjIJgdLCH",
        "colab_type": "text"
      },
      "source": [
        "Once the training is done, visit the [BigQuery Cloud Console](https://console.cloud.google.com/bigquery) and look at the model that has been trained. Then, come back to this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SRLxpccX_Tin"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_1.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Km_c9Ioq_Ti3",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_1 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "tkvddL88_Ti9",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.model_1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wf-9FBmL_Ti_"
      },
      "source": [
        "###Create the SQL statement to EVALUATE the Model_1 using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n2kdbiH_TjA",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_1 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "CsVBzNef_TjC",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.model_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw30UexH8v9P",
        "colab_type": "text"
      },
      "source": [
        "### EXTRACT hourofday from the pickup_datetime feature.\n",
        "\n",
        "As you recall, **pickup_datetime** is stored as a TIMESTAMP, where the Timestamp format is retrieved in the standard output format – year-month-day hour:minute:second (e.g. 2016-01-01 23:59:59).  Hourofaday returns the integer number representing the hour number of the given date.\n",
        "\n",
        "* Create a model titled \"model_2\"\n",
        "* EXTRACT the hourofday from the pickup_datetime feature to improve our model's rmse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa520N8KCIgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EXTRACT HourofDay from the pickup_datetime feature.\n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHeqcYz-B9F1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_2\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  pickuplon,\n",
        "  pickuplat,\n",
        "  dropofflon,\n",
        "  dropofflat\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DcE8o00kCiZX"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_2.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u2TU5nG6CiZe",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_2 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "h2yjF6uGCiZh",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.model_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_VLdHM_UCiZk"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_2 using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rp_uAeCwCiZk",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE the model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "bhfabG8XCiZm",
        "colab": {}
      },
      "source": [
        "#SOLUITON\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.model_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbOSxv6BDqB-",
        "colab_type": "text"
      },
      "source": [
        "### Feature cross dayofweek and hourofday \n",
        "\n",
        "First, let’s allow the model to learn traffic patterns by creating a new feature that combines the time of day and day of week (this is called a feature cross). \n",
        "\n",
        "* Modify model_2 to create a feature cross that combines the time of day and day of week.  Note:  CAST DAYOFWEEK and HOUR as strings.  Name the model \"model_3\".  \n",
        "\n",
        "* In this lab, we will modify the SQL to first use the CONCAT function to concatenate (feature cross) the dayofweek and hourofday features.  Then, we will use the ML.FEATURE_CROSS, BigQuery's new pre-processing feature cross function.\n",
        "\n",
        "Note:  BQML by default assumes that numbers are numeric features, and strings are categorical features.  We need to convert these features to strings because the Neural Network will treat 1,2,3,4,5,6,7 as numeric values.  Thus, there is no way to distinguish the time of day and day of week \"numerically.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_i3w3H7FXUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to feature cross the dayofweek and hourofday using the CONCAT function.\n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7l02C9KFMy7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_3\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
        "        CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
        "  pickuplon,\n",
        "  pickuplat,\n",
        "  dropofflon,\n",
        "  dropofflat\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbSRbuJ-fYtK",
        "colab_type": "text"
      },
      "source": [
        "### APPLY the ML.FEATURE_CROSS\n",
        "\n",
        "BigQuery ML now has ML.FEATURE_CROSS, a pre-processing function that performs a feature cross.  \n",
        "\n",
        "* ML.FEATURE_CROSS generates a STRUCT feature with all combinations of crossed categorical features, except for 1-degree items (the original features) and self-crossing items.  \n",
        "\n",
        "* Syntax:  ML.FEATURE_CROSS(STRUCT(features), degree)\n",
        "\n",
        "* The feature parameter is a categorical features separated by comma to be crossed. The maximum number of input features is 10. Unnamed feature is not allowed in features. Duplicates are not allowed in features.\n",
        "\n",
        "* Degree(optional): The highest degree of all combinations. Degree should be in the range of [1, 4]. Default to 2.\n",
        "\n",
        "Output: The function outputs a STRUCT of all combinations except for 1-degree items (the original features) and self-crossing items, with field names as concatenation of original feature names and values as the concatenation of the column string values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "Z3U2FxVklrlU",
        "colab": {}
      },
      "source": [
        "#The ML.Feature_Cross statement contains errors. Modify and run the query.\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_3\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  #CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
        "        #CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
        "  ML.FEATURE_CROSS(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING),\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  pickuplon,\n",
        "  pickuplat,\n",
        "  dropofflon,\n",
        "  dropofflat\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "CrjgmR6Qw5Z5",
        "colab": {}
      },
      "source": [
        "#Solution Code\n",
        "\n",
        "ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G6tpoYhcIgs4"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_3.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddMgHl21Igs9",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_3 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "t10fGqSfIgtA",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.model_3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8trDAbaGIgtC"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_3 using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8hD5EESgIgtC",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE the model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "uC-gyvAmIgtE",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.model_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsEA8hrEg8t",
        "colab_type": "text"
      },
      "source": [
        "# Applying Feature Engineering to BigQuery ML Models - PART 2\n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "* Derive a coordinate features\n",
        "* Feature cross coordinate features\n",
        "* Code cleanup\n",
        "* Apply the TRANSFORM clause\n",
        "* Evalute model performance\n",
        "\n",
        "\n",
        "## Introduction \n",
        "In this notebook, we continue using feature engineering to improve the prediction of the fare amount for a taxi ride in New York City. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NAPkAlEEg6C",
        "colab_type": "text"
      },
      "source": [
        "### Convert geolocation/coordinate features\n",
        "\n",
        "\n",
        "Pickup coordinate:\n",
        "*  pickup_longitude AS pickuplon\n",
        "*  pickup_latitude AS pickuplat\n",
        " \n",
        "\n",
        "\n",
        "Dropoff coordinate:\n",
        "*   #dropoff_longitude AS dropofflon\n",
        "*   #dropoff_latitude AS dropofflat\n",
        "\n",
        "**NOTES**:\n",
        "* The pick-up and drop-off longitude and latitude data are crucial to predicting the fare amount as fare amounts in NYC taxis are largely determined by the distance traveled.  Assuch, we need to  teach the model the Euclidean distance between the pick-up and drop-off points.  \n",
        "\n",
        "* Recall that latitude and longitude allows us to specify any location on Earth using a set of coordinates.  In our training data set, we restricted our data points to only pickups and drop offs within NYC. NYC has an approximate longitude range of -74.05 to -73.75 and a latitude range of 40.63 to 40.85.\n",
        "\n",
        "* The dataset contains information regarding the pickup and drop off coordinates. However, there is no information regarding the distance between the pickup and drop off points. Therefore, we create a new feature that calculates the distance between each pair of pickup and drop off points. We can do this using the Euclidean Distance, which is the straight-line distance between any two coordiante points.\n",
        "\n",
        "* We need to convert those coordinates into a single column of a spatial data type.  We will use the The ST_Distance function, which returns the minimum distance between two spatial objects.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCYniJnejNz0",
        "colab_type": "text"
      },
      "source": [
        "### Derive a coordinate features\n",
        "\n",
        "* Convert the feature coordinates into a single column of a spatial data type. Use the The ST_Distance function, which returns the minimum distance between two spatial objects.\n",
        "\n",
        "SAMPLE CODE:\n",
        "ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) AS euclidean\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6e4JoqrjvdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SQL STATEMENT HERE:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8mFocaKj9oA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_4\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  #CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
        "        #CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
        "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  #pickuplon,\n",
        "  #pickuplat,\n",
        "  #dropofflon,\n",
        "  #dropofflat,\n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "  AS euclidean\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uy7eK6iXlYPu"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_4.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2n-hmfy7lYP2",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_4 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "9atctYyGlYP7",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.model_4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YZp33wcIlYP_"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_4 using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CGly7xEElYQA",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE THE Model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "Lk42mvjzlYQE",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.model_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUoQmADkmlnV",
        "colab_type": "text"
      },
      "source": [
        "### Feature cross coordinate features\n",
        "\n",
        "In this section, we feature cross the pick-up and drop-off locations so that the model can learn pick-up-drop-off pairs that will require tolls.\n",
        "\n",
        "This step takes the geographic point corresponding to the pickup point and grids to a 0.1-degree-latitude/longitude grid (approximately 8km x 11km in New York—we should experiment with finer resolution grids as well). Then, it concatenates the pickup and dropoff grid points to learn “corrections” beyond the Euclidean distance associated with pairs of pickup and dropoff locations.\n",
        "\n",
        "Because the lat and lon by themselves don't have meaning, but only in conjunction, it may be useful to treat the fields as a pair instead of just using them as numeric values. However, lat and lon are continuous numbers, so we have to discretize them first. That's what SnapToGrid does. \n",
        "\n",
        "**REMINDER**: The ST_GEOGPOINT creates a GEOGRAPHY with a single point. ST_GEOGPOINT creates a point from the specified FLOAT64 longitude and latitude parameters and returns that point in a GEOGRAPHY value.  The ST_Distance function returns the minimum distance between two spatial objectsa.  It also returns meters for geographies and SRID units for geometrics.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVBfDDECoSBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The following feature cross coordinate code is incorrect.  Modify the code to feature cross the coordinate features. \n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_4\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  #CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
        "        #CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
        "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  #pickuplon,\n",
        "  #pickuplat,\n",
        "  #dropofflon,\n",
        "  #dropofflat,\n",
        " ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplat,pickuplon,pickuplat), 0.05)), \n",
        " ST_AsText(ST_GeogPoint(dropofflon, dropofflat,dropofflon), 0.04)) AS pickup_and_dropoff\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VjZawfZpQ7Y",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_5\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  #pickup_datetime,\n",
        "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
        "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
        "  CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
        "        CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
        "  #pickuplon,\n",
        "  #pickuplat,\n",
        "  #dropofflon,\n",
        "  #dropofflat,\n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "  AS euclidean,\n",
        "   CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
        "     ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01)))\n",
        "  AS pickup_and_dropoff\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zvOfj_k1qijv"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_5.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pzmlgfjjqij1",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE Model_5 here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab_type": "code",
        "cellView": "both",
        "id": "G8rM09jLqij4",
        "colab": {}
      },
      "source": [
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.model_5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EXpn2Wh0qij6"
      },
      "source": [
        "###Create the SQL statement to EVALUATE Model_5 using RMSE.  \n",
        "  \n",
        "Expand the elipses below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wCDt4qJuqij6",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE THE Model here.  \n",
        "Expand the elipses below to see the solution."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "CQUfOjPlqij8",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT SQRT(mean_squared_error) AS rmse FROM ML.EVALUATE(MODEL feat_eng.model_5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1dW3JLHrP5Z",
        "colab_type": "text"
      },
      "source": [
        "### Clean up the code to see where we are.\n",
        "\n",
        "Remove all the commented statements in the SQL statement.  We should now have a total of five input features for our model.  \n",
        "\n",
        "\n",
        "1. fare_amount\n",
        "2. passengers\n",
        "3. day_hr\n",
        "4. euclidean\n",
        "5. pickup_and_dropoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UxZXY18rWG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.revised_model_6_cleanup\n",
        "OPTIONS\n",
        "  (model_type='linear_reg',\n",
        "    input_label_cols=['fare_amount'])  \n",
        "AS\n",
        "SELECT\n",
        "  fare_amount,\n",
        "  passengers,\n",
        "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "  AS euclidean,\n",
        "   CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
        "     ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01)))\n",
        "  AS pickup_and_dropoff\n",
        "  \n",
        "FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pl6T5jbh74vg"
      },
      "source": [
        "### Apply the TRANSFORM clause\n",
        "\n",
        "Before we perform our prediction, we should encapsulate the entire feature set in a TRANSFORM clause.  BigQuery ML now supports defining data transformations during model creation, which will be automatically applied during prediction and evaluation. This is done through the TRANSFORM clause in the existing CREATE MODEL statement. By using the TRANSFORM clause, user specified transforms during training will be automatically applied during model serving (prediction, evaluation etc.) \n",
        "\n",
        "In our case, we are using the TRANSFORM clause to separate out the raw input data from the TRANSFORMED features.  The input columns of the TRANSFORM clause is the query_expr (AS SELECT part).  The output columns of TRANSFORM from select_list are used in training. These transformed columns are post-processed with standardization for numerics and one-hot encoding for categorical variables by default. \n",
        "\n",
        "The advantage of encapsulating features in the TRANSFORM is the client code doing the PREDICT doesn't change. Our model improvement is transparent to client code. Note that the TRANSFORM clause MUST be placed after the CREATE statement.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHySLekX74vw",
        "colab": {}
      },
      "source": [
        "#Below is a model titled \"final model\".  There are errors in the SQL statement.\n",
        "#Correct the model statements.\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.final_model\n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='linear_reg') \n",
        "AS\n",
        "TRANSFORM( \n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "      AS euclidean, \n",
        "  CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING),\n",
        "      CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday, \n",
        "  CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
        "     ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01))\n",
        "  ) AS pickup_and_dropoff\n",
        ")\n",
        " ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr\n",
        "  \n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='logistic_reg') \n",
        "\n",
        "SELECT * FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot6F95pK-Qcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        " \n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.final_model\n",
        "TRANSFORM(\n",
        "  fare_amount,\n",
        "  passengers, \n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "      AS euclidean, \n",
        "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
        "     ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01))\n",
        "  ) AS pickup_and_dropoff\n",
        ")\n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='linear_reg') \n",
        "AS\n",
        "\n",
        "SELECT * FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AVPXGKZ374v7"
      },
      "source": [
        "###Create two SQL statements to EVALUATE the final model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WPVQ3o2C74v9",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE final here.  \n",
        "#The solution is not provided.  Refer to previous solution for syntax/example."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5UfRE2Az1w",
        "colab_type": "text"
      },
      "source": [
        "# Applying Feature Engineering to BigQuery ML Models - PART 3\n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "* Create a predictioon model\n",
        "* Evalute model performance\n",
        "* Apply the bucketize function\n",
        "* L2 Regularization\n",
        "\n",
        "\n",
        "## Introduction \n",
        "In this notebook, we create a prediction model, evaluate the prediction model's performance, apply the bucketize function and re-evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIuFS56o_F2a",
        "colab_type": "text"
      },
      "source": [
        "### Model prediction\n",
        "\n",
        "\n",
        "Now that you have evaluated your model, the next step is to use it to predict an outcome. You use your model to predict the taxifare amount.  The ML.PREDICT function is used to predict results using your model: feat_eng.final_model.  \n",
        "\n",
        "Since this is a regression model (predicting a continuous numerical value), the best way to see how it performed is to evaluate the difference between the value predicted by the model and the ground truth benchmark score. We can do this with an ML.PREDICT query.\n",
        "\n",
        "MODIFY **THIS INCORRECT SQL STRATEMENT\"** before running the query.  Refer to the \"show code\" for the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qys4liHN_cI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery\n",
        "SELECT * FROM ML.EVALUATE(MODEL feat_eng.benchmark_model, (\n",
        "    -73.982683 AS pickuplon,\n",
        "    40.742104 AS pickuplat,\n",
        "    -73.983766 AS dropofflon,\n",
        "    40.755174 AS dropofflat,\n",
        "    3.0 AS passengers,\n",
        "    TIMESTAMP('2019-06-03 04:21:29.769443 UTC') AS pickup_datetime\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29cuS1CbADE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "SELECT * FROM ML.PREDICT(MODEL feat_eng.final_model, (\n",
        "  SELECT \n",
        "    -73.982683 AS pickuplon,\n",
        "    40.742104 AS pickuplat,\n",
        "    -73.983766 AS dropofflon,\n",
        "    40.755174 AS dropofflat,\n",
        "    3.0 AS passengers,\n",
        "    TIMESTAMP('2019-06-03 04:21:29.769443 UTC') AS pickup_datetime\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qmRnHZeAK6E",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE final model here.  \n",
        "#The solution is not provided.  Refer to previous solution for syntax/example."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kT968xDt9Sd4"
      },
      "source": [
        "### L2 Regularization\n",
        "\n",
        "Sometimes , the training RMSE is quite reasonable, but the evaluation RMSE is terrible. This is an indication of overfitting. When we do feature crosses, we run into the risk of overfitting (for example, when a particular day-hour combo doesn't have enough taxirides).\n",
        "\n",
        "* Modify final_model below to implement L2 Regularization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zfR5Q589glX",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.final_model\n",
        "TRANSFORM(\n",
        "  fare_amount,\n",
        "  passengers, \n",
        "  ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "      AS euclidean, \n",
        "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
        "  CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
        "  CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
        "     ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01))\n",
        "  ) AS pickup_and_dropoff\n",
        ")\n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='linear_reg', l2_reg=0.1) \n",
        "AS\n",
        "\n",
        "SELECT * FROM `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0QVuBOaX2kGL"
      },
      "source": [
        "### Apply the BUCKETIZE Function\n",
        "\n",
        "\n",
        "BigQuery ML now has BUCKETIZE, a pre-processing function that creats \"buckets\" (bins) - e.g. it bucketizes a continuous numerical feature into a string feature with bucket names as the value.\n",
        "\n",
        "* ML.BUCKETIZE(feature, split_points)\n",
        "\n",
        "* feature: A numerical column.\n",
        "\n",
        "* split_points: Array of numerical points to split the continuous values in feature into buckets. With n split points (s1, s2 … sn), there will be n+1 buckets generated. \n",
        "\n",
        "* Output: The function outputs a STRING for each row, which is the bucket name. bucket_name is in the format of bin_<bucket_number>, where bucket_number starts from 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8MaPXlt-4KmT",
        "colab": {}
      },
      "source": [
        "#Use the ML.BUCKETIZE function to EXTRACT the HOUR FROM pickup_datetime, creating three buckets of 5, 10, 17 as hourofday..  \n",
        "#CODE THE ENTIRE MODEL HERE.  Name the model \"bucket_model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9BkWSQx74Kzw",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.bucket_model\n",
        "TRANSFORM(fare_amount, passengers,\n",
        "          ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "              AS euclidean, \n",
        "          IF(EXTRACT(dayofweek FROM pickup_datetime) BETWEEN 2 and 6, 'weekday', 'weekend') as dayofweek,\n",
        "          ML.BUCKETIZE(EXTRACT(HOUR FROM pickup_datetime), [5, 10, 17]) AS hourofday\n",
        ")\n",
        "OPTIONS(input_label_cols=['fare_amount'], \n",
        "        model_type='linear_reg')\n",
        "AS\n",
        "SELECT \n",
        "fare_amount,\n",
        "passengers,\n",
        "pickup_datetime\n",
        "\n",
        "FROM  `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNOUZUWE8nnf",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE the model here.  \n",
        "#The solution is not provided.  Refer to previous solution for syntax/example."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ZCnBbY22ggn"
      },
      "source": [
        "### L2 Regularization with BUCKETIZATION\n",
        "\n",
        "Sometimes , the training RMSE is quite reasonable, but the evaluation RMSE is terrible. This is an indication of overfitting. When we do feature crosses, we run into the risk of overfitting (for example, when a particular day-hour combo doesn't have enough taxirides).\n",
        "\n",
        "* Modify bucket_model to implement L2 Regularization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQKUZtqx54Bb",
        "colab": {}
      },
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.bucket_model\n",
        "TRANSFORM(*EXCEPT(pickup_datetime), fare_amount, passengers,\n",
        "          ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "              AS euclidean, \n",
        "          IF(EXTRACT(dayofweek FROM pickup_datetime) BETWEEN 2 and 6, 'weekday', 'weekend') as dayofweek,\n",
        "          ML.BUCKETIZE(EXTRACT(HOUR FROM pickup_datetime), [5, 10, 17]) AS hourofday\n",
        ")\n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='linear_reg') \n",
        "\n",
        "AS\n",
        "SELECT \n",
        "*\n",
        "FROM  `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LSjoiKDl6Nok",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL feat_eng.bucket_model\n",
        "TRANSFORM(*EXCEPT(pickup_datetime)\n",
        "          ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) \n",
        "              AS euclidean, \n",
        "          IF(EXTRACT(dayofweek FROM pickup_datetime) BETWEEN 2 and 6, 'weekday', 'weekend') as dayofweek,\n",
        "          ML.BUCKETIZE(EXTRACT(HOUR FROM pickup_datetime), [5, 10, 17]) AS hourofday\n",
        ")\n",
        "OPTIONS(input_label_cols=['fare_amount'], model_type='linear_reg', l2_reg=0.1) \n",
        "\n",
        "AS\n",
        "SELECT \n",
        "*\n",
        "FROM  `feat_eng.feateng_training_data`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3VAbTUbf8uEj",
        "colab": {}
      },
      "source": [
        "#Create the SQL statement to EVALUATE the model here.  \n",
        "#The solution is not provided.  Refer to previous solution for syntax/example."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPdvM0fW_VrI"
      },
      "source": [
        "### LAK: \n",
        "Should we need to run the prediction model again - after L2 regularization -  as a best practice?\n",
        "\n"
      ]
    }
  ]
}